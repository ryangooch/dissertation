\chapter{Summary}
\label{sec:summary}

Data Discovery is an issue of extreme importance throughout the geosciences, where many petabytes of data have been produced, and the speed and quality of the production of the data have outstripped the ability to analyze and tag the data.
Efforts are ongoing throughout the field of geosciences to bridge this gap, enhancing cyberinfrastructure via modern computing and networking capabilities, along with developing the social aspects in managing the need for these developments.
Unfortunately, the effort to extend these advances to the subfield of weather radar data has not present to this point.

The research in this proposal details the current progress in efforts to apply transfer learning techniques to the problem of weather radar image classification, specifically with respect to colormapped images of weather radar data.
A set of experiments was detailed that confirm the capabilities of the chosen end-to-end deep learning model to learn to classify intensity data encoded in images.
Additionally, a hand-labeled dataset of weather radar reflectivity images was generated to aid in training said models, which in turn were used to discover more data.

Once a dataset was labeled and the classifier was trained, the model was deployed on two months worth of unseen data.
These two months were composed of over 85,000 weather radar images and would constitute a laborious, repetitive, and time-consuming task for a researcher if these images were labeled by hand from scratch.
Our first-pass classifier provided classifications on these images that resulted in many true positives, and in a fraction of the time, since each month was fully classified in about one hour on a laptop with GPU.
This first step was a major step forward in terms of historical data discovery of weather radar data as it provided reasonably accurate labels for precipitation regimes in weather radar scans for months' worth of data.

We also extended the effort by hand-curating the predictions on these two months of scans and ensuring false positives were corrected and placed into respective categories.
Utilizing a best-case model determined by theoretical inspection and empirical experimentation, and combining cutting-edge deep learning techniques, we then trained a new model architecture and deployed this on all scans spanning January 2019 through August 2019.
This dataset encompassed over 330,000 weather radar images.
Predicted labels matched climatological expections for the region and time frames, and spot checks of labeled images appear to be generally accurate.

This final effort produced a fully trained deep learning model capable of greater generalization ability, and can be used to identify precipitation regimes in data spanning years at a radar in a single day on constrained compute systems.
It is believed that our research will lead to more expedient data collection periods for researchers, allowing them to perform science more quickly as opposed to being forced to spend greater energy on data collection.
It is also believed that this research has only scraped the surface of what is possible in applying deep learning techniques to weather radar data.
For example, we believe that incorporating other weather radar variables such as specific differential phase and differential reflectivity will yield more accurate classifications, and that extending the model to incorporate these variables extends relatively straightforwardly, if the three-channel pseudo-image approach is used.
Additionally, utilizing more information available in dual-polarization variables may allow image segmentation to occur and lead to a greater number of classifiable categories within the images.
Image segmentation would allow a classifier to identify which pixels in an image correspond to not only stratiform and convective areas, but also may allow discovery of more localized features, such as gust fronts, hail cells, or performing hydrometeor identification.


